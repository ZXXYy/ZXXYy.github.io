<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 线形/非线形降维方法概述 | Xiaoye Zheng </title> <meta name="author" content="Xiaoye Zheng"> <meta name="description" content="Xiaoye Zheng' blog "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zxxyy.github.io/blog/2023/dim-reduction/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Xiaoye</span> Zheng </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Misc </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">Books</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/links/">Links</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">线形/非线形降维方法概述</h1> <p class="post-meta"> Created in July 03, 2023 by zxy </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>   ·   <a href="/blog/category/coding"> <i class="fa-solid fa-tag fa-sm"></i> Coding</a>   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> AI</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="绪论">绪论</h2> <h3 id="什么是降维">什么是降维</h3> <p>降维（dimensionality reduction）是指通过寻找数据的低维表示，将高维数据转化为更紧凑的形式。降维的目标是减少数据的维度，同时尽可能保留原始数据中的重要信息。降维的有效性基于一个假设：高维数据中存在冗余信息或重复表达的信息。</p> <p>在许多高维数据集中，存在大量的冗余信息或者可以被简化的重复表达。这意味着数据中的许多特征之间存在相关性或依赖关系，可以通过更低维的表示形式来捕捉这些关系，而不会丢失太多关键信息。通过降维，我们可以将数据映射到更低维的空间，从而消除或减少这些冗余信息，获得更紧凑的数据表示。</p> <p>我们希望通过一个函数f把一个d维的向量映射到k维上且不丢失任何重要的信息（k&lt;d），即</p> \[\boldsymbol{X}=\begin{bmatrix}x_1\\ x_2\\ \vdots\\ x_d\end{bmatrix}\rightarrow\boldsymbol{f}\left(\begin{bmatrix}x_1\\ x_2\\ \vdots\\ x_d\end{bmatrix}\right)=\begin{bmatrix}y_1\\ \vdots\\ y_k\end{bmatrix}=y\quad\text{with}\ k&lt;d\quad (1)\] <h3 id="为什么需要降维">为什么需要降维</h3> <p>在原始数据中各个特征之间存在着一定的信息冗余，随着特征的不断增加就容易出现“维数灾难”的问题。比如高维数据会导致计算上的挑战，很多传统的算法和方法在高维空间中需要更多的计算资源和时间，导致计算复杂度的急剧增加。降维可以帮助减少存储需求、提高计算效率，方便可视化和理解数据，去除冗余和噪声，防止过拟合，以及提高模型性能。</p> <h3 id="各种降维算法">各种降维算法</h3> <p>一般情况下降维方法分为：线性降维方法和非线性降维方法。</p> <p>线性降维方法的典型算法有：</p> <ul> <li>主成份分析 (PCA, Principal Component Analysis)</li> <li>线性判别分析 (LDA, Linear Discriminant Analysis）</li> <li>多尺度变换 (MDS, Multi-Dimensional Scaling)</li> </ul> <p>非线性降维方法有：</p> <ul> <li>保距特征映射 (ISOMAP) [2]</li> <li>局部线性嵌入 (LLE, Locally Linear Embedding) [1]</li> <li>拉普拉斯特征映射 (LE, Laplacian Eigenmap) [3]</li> <li>Maximum Variance Unfolding (MVU) [5]</li> </ul> <p>在接下来的章节中，我们将逐一介绍这些算法并对比各种方法。</p> <h2 id="线性降维方法">线性降维方法</h2> <p>线性降维方法的基本思想是通过线性变换将高维数据映射到低维空间。线性降维方法假设低维表示可以通过原始数据的线性组合来表示，从而在保留重要信息的同时减少数据的维度。</p> <p>线形映射函数通常更容易找到，即$(1)$中的函数$f$是一个线性映射，在此处用$\mathbf{w}$表示，则线性降维方法可以表示为：</p> \[\begin{bmatrix}x_1\\ x_2\\ \vdots\\ x_d\end{bmatrix}\Rightarrow\mathbf{w}\begin{bmatrix}x_1\\ x_2\\ \vdots\\ x_d\end{bmatrix}=\begin{bmatrix}\mathbf{w}_{11}&amp;\cdots&amp;\mathbf{w}_{1d}\\ \vdots&amp;&amp;\vdots\\ \mathbf{w}_{k_1}&amp;\cdots&amp;\mathbf{w}_{k_d}\end{bmatrix}\begin{bmatrix}x_1\\ x_2\\ \vdots\\ x_d\end{bmatrix}=\begin{bmatrix}\mathbf{y}_1\\ \vdots\\ \mathbf{y}_k\end{bmatrix}\quad\text{with k&lt;d}\] <h3 id="主成份分析">主成份分析</h3> <p>主成份分析 (PCA, Principal Component Analysis) 是一种最常用的<strong>无监督</strong>线性降维方法。它通过找到原始数据中方差最大的方向（主成分）来实现降维。这是一个强假设，因为可能存在在方差较小的方向上有原始数据相关的重要信息，但是通常来说，方差小的方向会是噪声~\cite{kPCA}。</p> <p>对于PCA主要步骤如下：</p> <p>对一组数据$X={x_1,x_2,…, x_n}$，其中$x_i$是一个$d$维的向量</p> <ol> <li>计算出样本均值 $\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n}x_i$</li> <li>去中心化，$z_i=x_i-\hat{\mu}$</li> <li>计算协方差矩阵 $S=\sum_{i=1}^{n}z_i z_i^t$</li> <li>计算$S$的特征向量和特征值，得到最大的$k$个特征值对应的特征向量 $e_1, e_2, …,e_k$</li> <li>$y = [e_1 \cdots e_k]^Tz$，如果数据$x$已被中心化，则$\mathbf{w}=[e_1 \cdots e_k]^T$</li> </ol> <h3 id="线性判别分析">线性判别分析</h3> <p>线性判别分析（Linear Discriminant Analysis，LDA）是一种经典的<strong>有监督</strong>线性降维方法，最开始是作为解决二分类问题由Fisher在1936年提出。LDA的主要目标是通过最大化不同类别之间的类间距离和最小化同类别内的类内距离，找到一个低维空间的投影，使得不同类别之间更易于区分。</p> <p>对于LDA主要步骤如下：</p> <p>对一组数据$X={(x_1,y_1),(x_2,y_2),…, (x_n,y_n)}$，其中$x_i$是一个$d$维的向量，$y_i \in {C_1, C_2}$ ，$C_1,C_2$为常数</p> <ol> <li> <p>计算类内散度矩阵$S_w=S_1+S_2=\sum_{y_i=C_1}(x_i-\mu_1)(x_i-\mu_1)^t+\sum_{y_i=C_2}(x_i-\mu_2)(x_i-\mu_2)^t$</p> <p>其中$\mu_j=\frac{1}{n_j}\sum_{y_i=C_j}x$</p> </li> <li> <p>计算类间散度矩阵$S_b=(\mu_{1}-\mu_{2})(\mu_{1}-\mu_{2})^{t}$</p> </li> <li> <p>计算矩阵$S_w^{-1}S_b$</p> </li> <li> <p>计算$S_w^{-1}S_b$的最大的$k$个特征值和对应的$k$个特征向量$e_1, e_2, …,e_k$</p> </li> <li> <p>得到投影矩阵$\mathbf{w}=[e_1 \cdots e_k]^T$</p> </li> </ol> <h3 id="多维尺度变换">多维尺度变换</h3> <p>最初的多尺度变换（Multi-Dimensional Scaling，MDS）是一种<strong>无监督</strong>线性降维方法，其目标是保持原始数据点之间的相对距离关系，尽可能地在低维空间中还原数据的结构。其中MDS又分为classical MDS和non-classical MDS：</p> <ul> <li> <p>Classical MDS(经典多维尺度变换):经典多维尺度变换的距离标准采用欧式距离。</p> </li> <li> <p>Non-classical MDS(非经典多维度尺度变换):非经典多维度尺度变换的距离标准采用非欧式距离s</p> </li> </ul> <p>对一组数据$X={x_1,x_2,…, x_n}$，定义一个距离矩阵$D=[d_{ij}:i,j=1,…,n]$，其中$d_{ij}$是两个样本点间的距离。多维尺度变换的优化目标是在低维欧氏空间$R^r$（通常是$R$或$R^2$）中找到一组点，使得它们之间的距离（或不相似度）尽可能接近于$d_{ij}$， MDS不针对$X$做映射，更关心的是距离矩阵$D$。</p> <p>对MDS来说其优化目标函数为：</p> \[\sum_{i=1}^n\sum_{j=1}^n(d_{ij}-d(\mathbf{y}_i,\mathbf{y}_j))^2.\] <p>对一组数据$X={x_1,x_2,…, x_n}$，其中$x_i$是一个$d$维的向量，经典多维尺度变换的主要步骤如下：</p> <ol> <li>计算样本的距离矩阵$D=[d_{ij}:i,j=1,…,n]$</li> <li> <p>构造矩阵$A=[a_{i,j}]=[-\frac{1}{2}d^2_{i,j}]$</p> </li> <li>构造中心化矩阵$B=HAH, H=I-\frac{1}{n}O$, 其中$I$为$n<em>n$的单位阵，$O$为$n</em>n$值均为1的矩阵</li> <li>对中心化矩阵 $B$ 进行特征值分解，得到最大的$k$个特征值对应的特征向量 $e_1, e_2, …,e_k$</li> <li>$y = [e_1 \cdots e_k]\Lambda_k^{\frac{1}{2}}$ ， 其中$\Lambda_k$为大的$k$个特征值构成的对角矩阵</li> </ol> <h2 id="非线形降维方法">非线形降维方法</h2> <p>与线性降维方法不同，非线性降维方法允许数据在降维过程中发生非线性变换，即$(1)$中的函数$f$非线性的，以更好地捕捉数据的内在结构和特征。常见的非线性降维方法有核主成分分析（Kernel Principal Component Analysis，Kernel PCA）、流形学习（Manifold Learning）、自编码器（Autoencoder）等。</p> <p>在本小节中主要介绍核主成分分析以及流形学习中的Isomap，LLE，LE算法并对比他们之间的关系。</p> <h3 id="kernel-pca">kernel PCA</h3> <p>核主成分分析（Kernel Principal Component Analysis，Kernel PCA）[8]是一种非线性降维方法，是主成分分析（PCA）在高维特征空间中的扩展。它通过应用核函数将数据映射到高维特征空间，从而在非线性情况下实现降维。</p> <p>对一组数据$X={x_1,x_2,…, x_n}$，其中$x_i$是一个$d$维的向量，现在用一个非线性映射$\phi$ 将$X$ 中的向量$x$ 映射到高维空间(记为$d$维)，即$\phi\left(\mathbf{x}\right):R^d\to R^t,t\gg d$, 映射$\phi$通常不显示给出，最后对该高维度空间的向量进行PCA分析。kPCA的主要步骤如下：</p> <ol> <li> <p>计算核矩阵$K=[k_{ij}: \phi(x_i)^T\phi(x_j)]$，对给定的数据集计算核矩阵，该矩阵描述了数据样本之间的相似度或内积。常用的核函数包括高斯核、多项式核、Sigmoid核等。</p> </li> <li>构造中心化核矩阵$B=HKH, H=I-\frac{1}{n}O$, 其中$I$为$n<em>n$的单位阵，$O$为$n</em>n$值均为1的矩阵</li> <li>对中心化矩阵 $B$ 进行特征值分解，得到最大的$k$个特征值$\lambda$对应的特征向量$u=[e_1, e_2, …,e_k]$</li> <li>$Y=\frac{1}{\sqrt{\lambda}}Ku$</li> </ol> <h3 id="kernel-lda">kernel LDA</h3> <p>核线性判别分析（Kernel Linear Discriminant Analysis）[6] 是一种非线性降维和分类方法，是线性判别分析（Linear Discriminant Analysis，LDA）在高维特征空间中的扩展。和kernel PCA类似，它通过应用核函数将数据映射到高维特征空间，从而在非线性情况下实现判别分析。总的来说，核LDA就是对中心化的核矩阵执行LAD。</p> <h3 id="isomap">Isomap</h3> <p>Isomap（Isometric Mapping）[2]是一种流形学习算法，基于MDS，用于非线性降维和数据可视化。它基于流形假设，认为高维数据分布在一个低维流形上，并试图在降维过程中保持样本之间的测地距离（geodesic distance）。总的来说，Isomap就是改变了MDS中距离的度量，利用最短路径算法（如Dijkstra算法）来估计数据点之间的测地距离。</p> <p>Isomap的主要步骤如下：</p> <ol> <li>构建邻接图，有两种方法：一种是指定半径阈值，半径内的点为邻近点；一种是使用K近邻算法，在邻近点之间基于欧式距离构建一个邻接图。</li> <li>计算最短路径距离：利用最短路径算法（如Dijkstra算法）计算邻接图中任意两个节点之间的最短路径距离。这些距离被认为是数据点之间的测地距离的近似。根据计算得到的最短路径距离，构建一个距离矩阵$D$，其中每个元素表示两个数据点之间的测地距离。</li> <li>构建距离矩阵，根据MDS线性降维算法对测地距离进行降维</li> </ol> <h3 id="局部线性嵌入">局部线性嵌入</h3> <p>局部线性嵌入 (LLE, Locally Linear Embedding)[1]算法由 Sam T.Roweis等人于2000年提出并发表在《Science》杂志上。该算法基于流形学习的思想，假设高维数据分布在一个低维流形上，并试图在降维过程中保持数据点之间的局部线性关系。LLE通过局部线性拟合来恢复全局的非线性结构，希望每个点与其邻近点的相对关系得以保持，即原来距离近的样本在新空间继续保持近的距离，而原来非常远的样本现在在哪并不关注。</p> <p>LLE的主要步骤如下：</p> <p>对一组数据$X={x_1,x_2,…, x_n}$，其中$x_i$是一个$d$维的向量，需要将$x_i$映射到$k$维的$y_i$向量上</p> <ol> <li> <p>寻找$x_i$的邻接点，可使用K近邻算法</p> </li> <li> <p>重构权重计算：对于每个数据点，通过最小化其与邻域点之间的重构误差，计算其与邻域点的重构权重。重构误差可通过最小二乘法求解。</p> <p>即最小化 $\varepsilon(W)=\sum\limits_{\mathrm{i}}\left|x_i-\sum_\mathrm{j}W_{\mathrm{ij}}x_j\right|^2$</p> <p>如果$x_j$为非近邻点，则$W_{ij}=0$，得到权重矩阵$W$</p> </li> <li> <p>构建了保持邻域关系的映射，高维度的$x_i$被映射到低维度的$y_i$，表示流形上的全局内部坐标，$y_i$的计算通过最小化嵌入代价函数来实现，即最小化 $\Phi(Y)=\sum_i\bigg|y_i-\sum_j W_{ij}y_j\bigg|^2$</p> </li> </ol> <p>​ 经过一系列数学推导，求解$y_i$即为求解矩阵$M$的最小$k$个非0特征值对应的特征向量$y_i$,</p> <p>​ 其中$M=(I-W)(I-W)^T$, $I$为单位矩阵</p> <h3 id="拉普拉斯特征映射">拉普拉斯特征映射</h3> <p>拉普拉斯特征映射 (LE, Laplacian Eigenmap) [3]基于图论和谱图理论的思想，通过构建数据的拉普拉斯矩阵和特征值分解，实现对数据的降维和特征提取。LE的主要思想是利用数据的局部邻域结构来构建一个图，并通过图的拉普拉斯矩阵来描述数据点之间的关系。LE和LLE非常相似，目标都是降维后尽量保持数据的局部分布而忽略全局分布。</p> <p>LE的主要步骤如下：</p> <ol> <li> <p>构建邻接图，有两种方法：一种是指定半径阈值，半径内的点为邻近点；一种是使用K近邻算法，在邻近点之间基于欧式距离构建一个邻接图。</p> </li> <li> <p>重构权重计算：如果点$x_i$和点 $x_j$相连，那么它们关系的权重可设定为热核函数$W_{ij}=e^{-\frac{|x_i-x_j|^2}{t}}$或简化为$W_{ij}=1$，否则$W_{ij}=0$</p> </li> <li> <p>进行特征映射，计算拉普拉斯矩阵$L=D-W$ 的特征向量与特征值，其中$D$是对角阵，$\begin{aligned} D_{ii}&amp; =\sum_j W_{ji}<br> \end{aligned}$</p> <p>即$Ly=\lambda Dy$，使用最小的 $k$个非零特征值对应的特征向量作为降维后的结果输出</p> </li> </ol> <h3 id="最大方差展开"><strong>最大方差展开</strong></h3> <p>最大方差展开（MVU, Maximum Variance Unfolding）[5]也叫做semidefinite embedding，基于数据的局部邻域结构和方差最大化的思想，通过优化一个目标函数来实现降维和数据展开。</p> <p>对一组数据$X={x_1,x_2,…, x_n}$，其中$x_i$是一个$d$维的向量，需要将$x_i$映射到$k$维的$y_i$向量上$k\ll d$</p> <p>MVU的优化目标是，给定一组边的集合$E$，使得$|\mathbf{y}_i-\mathbf{y}_j|\approx|\mathbf{x}_i-\mathbf{x}_j|\ \text{for}(i,j)\in E$</p> <p>MVU的主要步骤如下：</p> <ol> <li>使用K近邻算法构建邻接图，在邻近点之间基于欧式距离构建一个邻接图。</li> <li>使用半正定“展开”邻接图，与直接学习输出向量不同，半定法旨在找到一个内积矩阵，最大化邻域图中未连接的任意两个输入之间的距离，同时保持最近邻之间的距离。</li> <li>对内积矩阵应用MDS算法，获得降维后的向量。</li> </ol> <h2 id="总结">总结</h2> <p>我们通过一张表格总结上述提到的各种降维算法，并且比较他们之间的异同。</p> <table> <thead> <tr> <th>算法名称</th> <th>线性/非线性</th> <th>有监督/无监督</th> <th>优化目标</th> <th>优点</th> <th>缺点</th> </tr> </thead> <tbody> <tr> <td>PCA</td> <td>线性</td> <td>无监督</td> <td>降维后的低维样本之间每一维度方差尽可能大</td> <td>能够找到数据中最重要的特征或主成分，具有较高信息量</td> <td>计算复杂度高，低方差的特征可能会被忽略，导致部分信息损失。</td> </tr> <tr> <td>LDA</td> <td>线性</td> <td>有监督</td> <td>降维后同一类样本间协方差尽可能小，不同类中心距离尽可能大</td> <td>可以进行降维又可以进行分类，对于数据噪声和异常值具有一定的鲁棒性</td> <td>计算复杂度高，需要有标签的数据，LDA假设数据符合多元正态分布</td> </tr> <tr> <td>经典MDS</td> <td>线性</td> <td>无监督</td> <td>降维的同时保持数据点之间的相对距离关系</td> <td>通过改变距离函数MDS可以处理非线性关系的数据</td> <td>计算复杂度高，受限于距离度量，对噪声敏感</td> </tr> <tr> <td>kPCA</td> <td>非线性</td> <td>无监督</td> <td>核函数将数据映射到高维空间，再对高维空间降维，降维后的低维样本之间每一维度方差尽可能大</td> <td>PCA的非线性拓展</td> <td>计算复杂度高，需要调整超参数</td> </tr> <tr> <td>kLDA</td> <td>非线性</td> <td>有监督</td> <td>核函数将数据映射到高维空间，再对高维空间降维，降维后同一类样本间协方差尽可能小，不同类中心距离尽可能大</td> <td>LDA的非线性拓展</td> <td>计算复杂度高，需要调整超参数</td> </tr> <tr> <td>Isomap</td> <td>非线性</td> <td>无监督</td> <td>降维的同时保证高维数据的流型不变，即降维过程中保持样本之间的测地距离</td> <td>保持流形的全局几何结构，适用于学习内部平坦的低维流形</td> <td>计算复杂度较高，不适于学习有较大内在曲率的流形</td> </tr> <tr> <td>LLE</td> <td>非线性</td> <td>无监督</td> <td>降维后尽量保持数据的局部分布</td> <td>可以学习任意维的局部线性的低维流形，计算复杂度较低</td> <td>所学习的流形只能是不闭合的；要求样本在流形上是稠密采样的</td> </tr> <tr> <td>LE</td> <td>非线性</td> <td>无监督</td> <td>降维后尽量保持数据的局部分布</td> <td>效率高，使原空间中离得很近的点在低维空间也离得很近，可以用于聚类</td> <td>对算法参数和数据采样密度较敏感，不能有效保持流形的全局几何结构</td> </tr> <tr> <td>MVU</td> <td>非线性</td> <td>无监督</td> <td>降维后尽量保持数据的局部分布，且最大化数据点之间的方差</td> <td>尽可能保持数据的局部和全局结构，有噪声的数据时具有一定的鲁棒性</td> <td>性能受超参数影响大</td> </tr> </tbody> </table> <p>总的来说，kPCA、kLDA、 Isomap分别是PCA、LDA、经典MDS在非线性空间上的拓展。kPCA和kLDA采用核函数的方式将数据映射到高维空间，进而把问题转化为线性问题。而lsomap采用测地距离的方式来保证高维数据的流型不变。</p> <p>对于非线形降维，Isomap、LE、LLE均利用了局部近邻的信息来构建针对流型的全局嵌入。但相对Isomap关注整个流型的全局特征，LLE和LE算法仅仅关注样本的局部分布。从计算的角度来说，Isomap和MVU在降维时会一个密集矩阵，而LE和LLE算法构建了一个稀疏矩阵。</p> <p>为了更好的理解这些非线形降维算法之间的关系，Ham等人[4]指出，Isomap、LE、LLE这三种算法均可以转化为kPCA。Xiao [7]等人用统一的对偶形式表示了Isomap、LE、LLE以及MVU这四种算法，并说明了这些算法间的联系。</p> <h2 id="参考文献">参考文献</h2> <p>[1] Roweis, Sam T., and Lawrence K. Saul. “Nonlinear dimensionality reduction by locally linear embedding.” <em>science</em> 290.5500 (2000): 2323-2326.</p> <p>[2] Tenenbaum, Joshua B., Vin de Silva, and John C. Langford. “A global geometric framework for nonlinear dimensionality reduction.” <em>science</em> 290.5500 (2000): 2319-2323.</p> <p>[3] Belkin, Mikhail, and Partha Niyogi. “Laplacian eigenmaps for dimensionality reduction and data representation.” <em>Neural computation</em> 15.6 (2003): 1373-1396.</p> <p>[4] Ham, Jihun, et al. “A kernel view of the dimensionality reduction of manifolds.” <em>Proceedings of the twenty-first international conference on Machine learning</em>. 2004.</p> <p>[5] Weinberger, Kilian Q., and Lawrence K. Saul. “An introduction to nonlinear dimensionality reduction by maximum variance unfolding.” <em>AAAI</em>. Vol. 6. 2006.</p> <p>[6] Mika, Sebastian, et al. “Fisher discriminant analysis with kernels.” <em>Neural networks for signal processing IX: Proceedings of the 1999 IEEE signal processing society workshop (cat. no. 98th8468)</em>. Ieee, 1999.</p> <p>[7] Xiao, Lin, Jun Sun, and Stephen Boyd. “A duality view of spectral methods for dimensionality reduction.” <em>Proceedings of the 23rd international conference on Machine learning</em>. 2006.</p> <p>[8] Schölkopf, Bernhard, Alexander Smola, and Klaus-Robert Müller. “Kernel principal component analysis.” <em>International conference on artificial neural networks</em>. Berlin, Heidelberg: Springer Berlin Heidelberg, 1997.</p> <h3 id="参考博客">参考博客</h3> <p>https://www.cnblogs.com/pinard/p/6239403.html</p> <p>https://www.showmeai.tech/article-detail/198</p> <p>https://chenrudan.github.io/blog/2016/04/01/dimensionalityreduction.html#1</p> <p>http://blog.codinglabs.org/articles/pca-tutorial.html</p> <p>https://leovan.me/cn/2018/03/manifold-learning/#fn:1</p> <p>https://www.cnblogs.com/pinard/p/6244265.html</p> <p>https://rich-d-wilkinson.github.io/MATH3030/6.1-classical-mds.html#non-euclidean-distance-matrices</p> <p>https://0809zheng.github.io/2021/07/27/kpca.html</p> <p>https://zhuanlan.zhihu.com/p/59775730</p> <p>https://zhuanlan.zhihu.com/p/434098745</p> <p>https://tianchi.aliyun.com/forum/post/79400</p> <p>https://www.cs.cmu.edu/~ggordon/10725-F12/scribes/10725_Lecture21.pdf</p> <p>https://en.wikipedia.org/wiki/Semidefinite_embedding</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/solana-concepts/">Solana Core Concepts: Accounts, Programs, and PDAs</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/python-asyncio/">Python3 Concurrency: asyncio module/async/await</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/python-cheat-sheet/">Python Cheat Sheet</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/raft-leader/">MIT6.824 Lab2A Raft Leader Election</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/top/">Linux中的top command</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Xiaoye Zheng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"Publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-repositories",title:"Repositories",description:"",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"dropdown-books",title:"Books",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-links",title:"Links",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"post-solana-core-concepts-accounts-programs-and-pdas",title:"Solana Core Concepts: Accounts, Programs, and PDAs",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/solana-concepts/"}},{id:"post-python3-concurrency-asyncio-module-async-await",title:"Python3 Concurrency: asyncio module/async/await",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/python-asyncio/"}},{id:"post-python-cheat-sheet",title:"Python Cheat Sheet",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/python-cheat-sheet/"}},{id:"post-mit6-824-lab2a-raft-leader-election",title:"MIT6.824 Lab2A Raft Leader Election",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/raft-leader/"}},{id:"post-linux\u4e2d\u7684top-command",title:"Linux\u4e2d\u7684top command",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/top/"}},{id:"post-arm\u4ea4\u53c9\u7f16\u8bd1\u5de5\u5177\u94fe\u4e0e\u7f16\u8bd1\u9009\u9879",title:"ARM\u4ea4\u53c9\u7f16\u8bd1\u5de5\u5177\u94fe\u4e0e\u7f16\u8bd1\u9009\u9879",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/cross-compile/"}},{id:"post-mit6-824-lab1-map-reduce",title:"MIT6.824 Lab1 Map Reduce",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/map-reduce/"}},{id:"post-\u4f7f\u7528gcov-lcov\u6d4b\u8bd5\u7528\u4f8b\u7684\u4ee3\u7801\u8986\u76d6\u7387",title:"\u4f7f\u7528gcov/lcov\u6d4b\u8bd5\u7528\u4f8b\u7684\u4ee3\u7801\u8986\u76d6\u7387",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/gcov/"}},{id:"post-rust\u7f16\u8bd1\u5668\u521d\u63a2-rust\u7f16\u8bd1\u5668\u662f\u5982\u4f55\u5de5\u4f5c\u7684",title:"rust\u7f16\u8bd1\u5668\u521d\u63a2\uff1aRust\u7f16\u8bd1\u5668\u662f\u5982\u4f55\u5de5\u4f5c\u7684",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/rustc/"}},{id:"post-linux-kvm-x86\u5185\u5b58\u865a\u62df\u5316ept\u6e90\u4ee3\u7801\u5206\u6790",title:"Linux KVM x86\u5185\u5b58\u865a\u62df\u5316EPT\u6e90\u4ee3\u7801\u5206\u6790",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/kvm-mem-source/"}},{id:"post-linux-kvm-x86-cpu\u865a\u62df\u5316\u539f\u7406\u53ca\u6e90\u4ee3\u7801\u5206\u6790",title:"Linux KVM x86 CPU\u865a\u62df\u5316\u539f\u7406\u53ca\u6e90\u4ee3\u7801\u5206\u6790",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/kvm-cpu-virt/"}},{id:"post-\u8ba9google\u641c\u7d22\u5230\u4f60\u7684github\u7f51\u9875-\u4f7f\u7528jekyll\u642d\u5efa",title:"\u8ba9Google\u641c\u7d22\u5230\u4f60\u7684Github\u7f51\u9875\uff08\u4f7f\u7528Jekyll\u642d\u5efa\uff09",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/add-Google-search/"}},{id:"post-x86\u5185\u5b58\u865a\u62df\u5316-\u5f71\u5b50\u9875\u8868-shadow-page-table-\u548c\u62d3\u5c55\u9875\u8868-ept",title:"x86\u5185\u5b58\u865a\u62df\u5316--\u5f71\u5b50\u9875\u8868(Shadow Page Table)\u548c\u62d3\u5c55\u9875\u8868(EPT)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/SPT-EPT/"}},{id:"post-rust\u88f8\u6307\u9488-\u5f15\u7528-slice-box-vec-string\u7684\u5185\u5b58\u5e03\u5c40\u53ca\u8f6c\u6362",title:"Rust\u88f8\u6307\u9488,\u5f15\u7528,slice,box,vec,string\u7684\u5185\u5b58\u5e03\u5c40\u53ca\u8f6c\u6362",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/rust-type-mem-layout/"}},{id:"post-virtualization-tools-overwiew-for-layman",title:"Virtualization Tools Overwiew for Layman",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/virtualization-tools/"}},{id:"post-rust-cheat-sheet-in-practice",title:"Rust Cheat Sheet in Practice",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/rust-cheat-sheet/"}},{id:"post-\u7ebf\u5f62-\u975e\u7ebf\u5f62\u964d\u7ef4\u65b9\u6cd5\u6982\u8ff0",title:"\u7ebf\u5f62/\u975e\u7ebf\u5f62\u964d\u7ef4\u65b9\u6cd5\u6982\u8ff0",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/dim-reduction/"}},{id:"post-qemu-kvm\u4e2d\u7684\u7f51\u7edc\u865a\u62df\u5316-part2-user-networking",title:"QEMU/KVM\u4e2d\u7684\u7f51\u7edc\u865a\u62df\u5316--Part2 User Networking",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/qemu-network-slirp/"}},{id:"post-qemu-kvm-rust\u76f8\u5173\u5165\u95e8\u8d44\u6e90\u6574\u7406",title:"QEMU/KVM Rust\u76f8\u5173\u5165\u95e8\u8d44\u6e90\u6574\u7406",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/kvm-101/"}},{id:"post-qemu-kvm\u4e2d\u7684\u7f51\u7edc\u865a\u62df\u5316-part1-overview",title:"QEMU/KVM\u4e2d\u7684\u7f51\u7edc\u865a\u62df\u5316--Part1 Overview",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/qemu-network/"}},{id:"post-meltdown\u539f\u7406\u53caseed-lab\u5b9e\u9a8csetup",title:"Meltdown\u539f\u7406\u53caSEED Lab\u5b9e\u9a8csetup",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/meltdown/"}},{id:"post-frp-learning-notes\u53ca\u76f8\u5173\u914d\u7f6e\u64cd\u4f5c",title:"frp learning notes\u53ca\u76f8\u5173\u914d\u7f6e\u64cd\u4f5c",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/frp/"}},{id:"post-adaboosting-learning-notes",title:"AdaBoosting Learning notes",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/AdaBoosting/"}},{id:"post-\u533a\u522barm\u4e0b\u7684armv9-a32-aarch64-cortex",title:"\u533a\u522bARM\u4e0b\u7684Armv9, A32, AArch64, Cortex...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/ARM_architect/"}},{id:"post-gdb\u5165\u95e8-\u5e38\u7528\u6307\u4ee4-\u811a\u672c-\u63d2\u4ef6",title:"GDB\u5165\u95e8\uff1a\u5e38\u7528\u6307\u4ee4\u3001\u811a\u672c\u3001\u63d2\u4ef6",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/gdb_command/"}},{id:"post-ds-store\u662f\u4ec0\u4e48-\u600e\u4e48\u5220\u9664",title:".DS_store\u662f\u4ec0\u4e48\uff1f\u600e\u4e48\u5220\u9664\uff1f",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/DS_store/"}},{id:"post-jekyll-learning-notes",title:"Jekyll Learning Notes",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/jekyll/"}},{id:"post-useful-websites-amp-shortcuts",title:"Useful Websites & shortcuts",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/useful-web/"}},{id:"post-support-vector-machine-svm-learning-notes",title:"Support Vector Machine (SVM) Learning notes",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/SVM/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%78%69%61%6F%79%65%7A@%7A%6A%75.%65%64%75.%63%6E","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=LJFW4ZIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/ZXXYy","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>